ü§ñ AI Scorer Pro: Automated Exam Paper Evaluation SystemProject OverviewThe AI Scorer Pro is an innovative academic project designed to automate the traditionally time-consuming, tedious, and potentially biased process of manually grading subjective, handwritten answer sheets1111. By integrating advanced Handwriting Recognition (HWR), Natural Language Processing (NLP), and a Django web framework, the system provides objective scores and actionable feedback, targeting an accuracy comparable to human evaluators (75-85%)2222.The core innovation is semantic matching‚Äîevaluating the conceptual meaning of the student's response‚Äîrather than relying solely on simple word-for-word comparison3333.‚ú® Core System Features1. Advanced Evaluation MetricsThe final mark is calculated based on a weighted model that moves beyond keyword count to score conceptual understanding:Semantic Scoring: Utilizes TF-IDF Vectorization and Cosine Similarity to quantify the conceptual similarity between the student's answer and the master key4.Multi-Criteria Grading: Scores are derived from a composite of five factors: Keyword Presence, Semantic Match, Lexical Accuracy, Grammar Score (using SpaCy), and Keyword Order Accuracy (for procedural questions)5555.2. Handwriting Recognition (HWR)Extraction: Extracts text from scanned answer sheets using a Tesseract OCR engine (serving as a placeholder for the more advanced VGG-19 with GRU (CRNN) deep learning architecture suggested in the research)6666.Visualizer (UX): The Faculty Report includes an interactive HTML Canvas that displays the uploaded image with simulated bounding boxes and highlights, visually demonstrating the text recognition process.3. Role-Based PortalsThe application uses a responsive Bootstrap interface with distinct views for different user roles:Faculty/Evaluator Portal: Allows configuration of Key Answers via the Django Admin, handles image uploads, and grants access to the detailed metric report for analysis.Student Portal: Allows students to search for their results, displaying only the final score and personalized feedback (e.g., "Essential keywords were missing"), ensuring privacy and focus on improvement7777.üõ†Ô∏è Technology StackComponentTechnologyPurposeBackend FrameworkDjango (Python)Web framework for routing, MVT architecture, and media file handling.HWR/OCRPyTesseract / Tesseract OCRConverts image data (handwriting) into strings.NLP & ScoringScikit-learn, SpaCy, NLTK, FuzzyWuzzyHandles vectorization, similarity calculation, grammar checking, and lexical matching.ML FrameworkTensorFlow/Keras (Future Implementation)Base libraries for the suggested VGG-19 with GRU model8888.Frontend/UXHTML5, Bootstrap 5, JavaScript/CanvasResponsive design and visual demonstration of the HWR process.üöÄ Installation and SetupPrerequisitesPython 3.8+GitTesseract OCR Engine: Must be installed on your operating system (required for PyTesseract).Setup InstructionsClone the Repository:Bashgit clone [YOUR_REPOSITORY_URL]
cd ExamAutoEval
Create and Activate Virtual Environment:Bashpython -m venv venv
source venv/bin/activate  # macOS/Linux
# venv\Scripts\activate   # Windows
Install Dependencies:Bashpip install -r requirements.txt
Download NLTK/SpaCy Data:(The project requires NLTK/SpaCy data to be installed in the nltk_data directory.)Bashpython
import nltk
import spacy

# Download essential NLTK tokens
nltk.download(['punkt', 'punkt_tab', 'stopwords'])

# Download SpaCy model (essential for Grammar checking)
spacy.cli.download("en_core_web_sm")

exit()
Database Migration:Bashpython manage.py makemigrations evaluator
python manage.py migrate
Create Superuser: (Access the Admin interface to define Key Answers)Bashpython manage.py createsuperuser
Run the Server:Bashpython manage.py runserver
Access the application at http://127.0.0.1:8000/.üìö Academic Validation (V. Experimental Analysis)The project requires validation against human grading:Define Keys: Add your sample questions and key answers via the Django Admin.Run Tests: Upload 10-15 sample handwritten sheets and record the "System Mark."Validate: Compare the System Mark against a manually assigned "Faculty Mark" to calculate the system's Accuracy Percentage. This result forms the core evidence of the system's effectiveness.üí° Future EnhancementsIntegration of the fully trained VGG-19 with GRU CRNN model for state-of-the-art HWR accuracy.Extension of the NLP pipeline to evaluate handwritten mathematical formulas and diagrams9.Implementation of background processing for high-volume batch grading.
